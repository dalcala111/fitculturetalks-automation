name: "Ultimate RunwayML Deuce Dancing Generator"
on:
  repository_dispatch:
    types: [trigger-midjourney, create-masterpiece, trigger-shih-tzu-food-video, trigger-shih-tzu-video-reference]
  workflow_dispatch:
    inputs:
      prompt:
        description: 'Image generation prompt'
        required: true
        default: 'Deuce the adorable Shih Tzu dancing like a human next to delicious trending food dish'
      animation_type:
        description: 'Animation type (dancing, eating, emergence)'
        required: false
        default: 'dancing'
jobs:
  runwayml-deuce-generator:
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up job
      run: echo "üé¨ Starting Ultimate RunwayML Deuce Human-Like Dancing mission"
      
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Clean Previous Files
      run: |
        echo "üßπ Cleaning previous images and artifacts..."
        rm -f dalle_generation_*.png
        rm -f runwayml_generation_*.mp4
        rm -f dalle_generation_*.jpg
        rm -f *.png
        rm -f *.jpg
        rm -f final_animation.mp4
        rm -f *.mp4
        rm -f *.mp3
        rm -f *.wav
        rm -f reference_video.*
        echo "‚úÖ Previous files cleared"
        echo "üìÅ Current directory after cleanup:"
        ls -la

    # UPDATED: Download Reference Video Step
    - name: Download Reference Video
      if: github.event.client_payload.use_video_reference == true
      env:
        REFERENCE_VIDEO_URL: ${{ github.event.client_payload.reference_video_url }}
        SELECTED_DANCE: ${{ github.event.client_payload.selected_dance || 'macarena' }}
      run: |
        echo "üé• Downloading reference video for $SELECTED_DANCE dance..."
        echo "üì∫ URL: $REFERENCE_VIDEO_URL"
        
        # Download from your GitHub repository (no yt-dlp needed!)
        curl -L -o "reference_video.mp4" "$REFERENCE_VIDEO_URL"
        
        # Verify download
        if [ -f "reference_video.mp4" ]; then
          echo "‚úÖ Reference video downloaded successfully!"
          ls -la reference_video.mp4
          
          # Get video info
          sudo apt-get update && sudo apt-get install -y ffmpeg
          echo "üìä Reference video info:"
          ffprobe -v quiet -print_format json -show_format -show_streams reference_video.mp4 | head -20
        else
          echo "‚ùå Failed to download reference video"
          exit 1
        fi
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        # Update pip and install from requirements
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        echo "üì¶ Installed packages:"
        pip list

    - name: Debug Enhanced Deuce Dancing Payload
      env:
        PROMPT: ${{ github.event.client_payload.runway_prompt || github.event.client_payload.prompt || github.event.inputs.prompt || 'Deuce the adorable Shih Tzu dancing like a human next to delicious trending food dish' }}
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || github.event.inputs.animation_type || 'dancing' }}
        DANCING_MOTION_PROMPT: ${{ github.event.client_payload.dancing_motion_prompt }}
        RUNWAY_NEGATIVE_PROMPT: ${{ github.event.client_payload.runway_negative_prompt }}
        USE_VIDEO_REFERENCE: ${{ github.event.client_payload.use_video_reference || 'false' }}
        REFERENCE_VIDEO_URL: ${{ github.event.client_payload.reference_video_url }}
        SELECTED_DANCE: ${{ github.event.client_payload.selected_dance }}
        REFERENCE_STRENGTH: ${{ github.event.client_payload.runway_settings.reference_strength || '0.8' }}
        VIDEO_TO_VIDEO: ${{ github.event.client_payload.runway_settings.video_to_video || 'false' }}
        CAMERA_MOTION: ${{ github.event.client_payload.runway_settings.camera_motion || '0' }}
        MOTION_STRENGTH: ${{ github.event.client_payload.runway_settings.motion_strength || '6' }}
        MOTION_GUIDANCE: ${{ github.event.client_payload.runway_settings.motion_guidance || '12' }}
        MOTION_SEED: ${{ github.event.client_payload.runway_settings.seed }}
        DURATION: ${{ github.event.client_payload.runway_settings.duration || '10' }}
        FPS: ${{ github.event.client_payload.runway_settings.fps || '30' }}
        RESOLUTION: ${{ github.event.client_payload.runway_settings.resolution || '1080x1920' }}
        MODEL: ${{ github.event.client_payload.runway_settings.model || 'gen3a' }}
        ASPECT_RATIO: ${{ github.event.client_payload.runway_settings.aspect_ratio || '9:16' }}
        WATERMARK: ${{ github.event.client_payload.runway_settings.watermark || 'false' }}
        RUNWAYML_API_KEY: ${{ secrets.RUNWAYML_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        echo "üîç Debug: Enhanced Deuce Dancing Parameters..."
        echo "Primary prompt: $PROMPT"
        echo "Deuce dancing motion prompt: $DANCING_MOTION_PROMPT"
        echo "Negative prompt: $RUNWAY_NEGATIVE_PROMPT"
        echo "üé• VIDEO REFERENCE MODE: $USE_VIDEO_REFERENCE"
        echo "üì∫ Reference video URL: $REFERENCE_VIDEO_URL"
        echo "üíÉ Selected dance: $SELECTED_DANCE"
        echo "üéØ Reference strength: $REFERENCE_STRENGTH"
        echo "üé¨ Video-to-video mode: $VIDEO_TO_VIDEO"
        echo "Camera motion: $CAMERA_MOTION (0 = static)"
        echo "Motion strength: $MOTION_STRENGTH"
        echo "Motion guidance: $MOTION_GUIDANCE"
        echo "Motion seed: $MOTION_SEED"
        echo "Duration: $DURATION seconds"
        echo "FPS: $FPS"
        echo "Resolution: $RESOLUTION"
        echo "Model: $MODEL"
        echo "Aspect ratio: $ASPECT_RATIO"
        echo "Watermark: $WATERMARK"
        echo "Animation type: $ANIMATION_TYPE"
        echo "RunwayML API key configured: $([[ -n "$RUNWAYML_API_KEY" ]] && echo "‚úÖ Yes" || echo "‚ùå No")"
        
    - name: Run Enhanced RunwayML Deuce Dancing Video Generator
      env:
        # Primary prompt settings
        PROMPT: ${{ github.event.client_payload.runway_prompt || github.event.client_payload.prompt || github.event.inputs.prompt || 'Deuce the adorable Shih Tzu dancing like a human next to delicious trending food dish' }}
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || github.event.inputs.animation_type || 'dancing' }}
        
        # VIDEO REFERENCE SETTINGS
        USE_VIDEO_REFERENCE: ${{ github.event.client_payload.use_video_reference || 'false' }}
        REFERENCE_VIDEO_URL: ${{ github.event.client_payload.reference_video_url }}
        SELECTED_DANCE: ${{ github.event.client_payload.selected_dance || 'macarena' }}
        REFERENCE_STRENGTH: ${{ github.event.client_payload.runway_settings.reference_strength || '0.8' }}
        VIDEO_TO_VIDEO: ${{ github.event.client_payload.runway_settings.video_to_video || 'false' }}
        
        # Enhanced dancing-specific motion settings from consolidated runway_settings
        DANCING_MOTION_PROMPT: ${{ github.event.client_payload.dancing_motion_prompt }}
        RUNWAY_NEGATIVE_PROMPT: ${{ github.event.client_payload.runway_negative_prompt }}
        CAMERA_MOTION: ${{ github.event.client_payload.runway_settings.camera_motion || '0' }}
        MOTION_STRENGTH: ${{ github.event.client_payload.runway_settings.motion_strength || '6' }}
        MOTION_GUIDANCE: ${{ github.event.client_payload.runway_settings.motion_guidance || '12' }}
        MOTION_SEED: ${{ github.event.client_payload.runway_settings.seed }}
        UPSCALE: ${{ github.event.client_payload.runway_settings.upscale || 'true' }}
        
        # Enhanced generation parameters from consolidated runway_settings
        DURATION: ${{ github.event.client_payload.runway_settings.duration || '10' }}
        FPS: ${{ github.event.client_payload.runway_settings.fps || '30' }}
        RESOLUTION: ${{ github.event.client_payload.runway_settings.resolution || '1080x1920' }}
        MODEL: ${{ github.event.client_payload.runway_settings.model || 'gen3a' }}
        ASPECT_RATIO: ${{ github.event.client_payload.runway_settings.aspect_ratio || '9:16' }}
        WATERMARK: ${{ github.event.client_payload.runway_settings.watermark || 'false' }}
        INTERPOLATE: ${{ github.event.client_payload.runway_settings.interpolate || 'true' }}
        LOOP: ${{ github.event.client_payload.runway_settings.loop || 'false' }}
        
        # Enhanced motion settings from consolidated motion_config
        SUBJECT_AREA: ${{ github.event.client_payload.motion_config.subject_area || 'deuce_shih_tzu_character' }}
        MOTION_TYPE: ${{ github.event.client_payload.motion_config.motion_type || 'human_like_dancing_movement' }}
        MOTION_DIRECTION: ${{ github.event.client_payload.motion_config.motion_direction || 'upright_anthropomorphic_dancing' }}
        MOTION_INTENSITY: ${{ github.event.client_payload.motion_config.motion_intensity || 'high_fluid_human_like' }}
        STATIC_AREAS: ${{ github.event.client_payload.motion_config.static_areas || 'background_plate_edges' }}
        PRIMARY_MOTION: ${{ github.event.client_payload.motion_config.primary_motion || 'deuce_upright_human_like_dancing_movement_smooth_fluid' }}
        SECONDARY_MOTION: ${{ github.event.client_payload.motion_config.secondary_motion || 'front_paws_as_arms_human_gestures_continuous_flow' }}
        TERTIARY_MOTION: ${{ github.event.client_payload.motion_config.tertiary_motion || 'head_bobbing_rhythmic_bouncing_seamless_motion' }}
        
        # Quality specs from consolidated quality_specs
        STYLE: ${{ github.event.client_payload.quality_specs.style || 'realistic_photography_natural_lighting_photorealistic' }}
        LIGHTING: ${{ github.event.client_payload.quality_specs.lighting || 'natural_warm_professional_food_photography_cinematic' }}
        COMPOSITION: ${{ github.event.client_payload.quality_specs.composition || 'centered_close_up_frontal_stable_framing' }}
        CHARACTER: ${{ github.event.client_payload.quality_specs.character || 'deuce_the_shih_tzu_anthropomorphic_dancer_fluid_motion' }}
        MOTION_QUALITY: ${{ github.event.client_payload.quality_specs.motion_quality || 'smooth_seamless_professional_choreography' }}
        
        # Quality enhancer arrays (join them as comma-separated strings)
        MOTION_DESCRIPTORS: ${{ join(github.event.client_payload.quality_specs.motion_descriptors, ',') || 'smooth,fluid,continuous,seamless,rhythmic' }}
        CAMERA_STABILITY: ${{ join(github.event.client_payload.quality_specs.camera_stability, ',') || 'static,no_movement,fixed_composition,stable_framing' }}
        DANCE_QUALITY: ${{ join(github.event.client_payload.quality_specs.dance_quality, ',') || 'professional_choreography,human_like_gestures,anthropomorphic_behavior' }}
        VISUAL_QUALITY: ${{ join(github.event.client_payload.quality_specs.visual_quality, ',') || 'photorealistic,natural_lighting,cinematic_quality' }}
        
        # Dancing sequence phases from dance_sequence
        PHASE_1: ${{ github.event.client_payload.dance_sequence.phase_1 || 'deuce_stands_upright_on_hind_legs_like_human_smooth_transition_0_to_2s' }}
        PHASE_2: ${{ github.event.client_payload.dance_sequence.phase_2 || 'human_like_dancing_swaying_arm_movements_fluid_motion_2_to_4s' }}
        PHASE_3: ${{ github.event.client_payload.dance_sequence.phase_3 || 'upright_dancing_paws_as_arms_rhythmic_movement_continuous_4_to_6s' }}
        PHASE_4: ${{ github.event.client_payload.dance_sequence.phase_4 || 'complex_human_dance_moves_while_standing_upright_seamless_6_to_8s' }}
        PHASE_5: ${{ github.event.client_payload.dance_sequence.phase_5 || 'celebrating_finish_pose_upright_paws_raised_smooth_8_to_10s' }}
        
        # API keys
        RUNWAYML_API_KEY: ${{ secrets.RUNWAYML_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        N8N_WEBHOOK: ${{ secrets.N8N_WEBHOOK }}
      run: |
        echo "üé¨ Generating ENHANCED animated Deuce dancing video with RunwayML..."
        echo "üï∫ Human-like dancing animation with STATIC camera and enhanced motion quality"
        echo "Animation type: $ANIMATION_TYPE"
        echo "üé• Using video reference: $USE_VIDEO_REFERENCE"
        echo "üíÉ Dance type: $SELECTED_DANCE"
        echo "üéØ Reference strength: $REFERENCE_STRENGTH"
        echo "üé¨ Video-to-video mode: $VIDEO_TO_VIDEO"
        echo "Camera motion: $CAMERA_MOTION (0 = completely static)"
        echo "Motion strength: $MOTION_STRENGTH (enhanced for better dance moves)"
        echo "Motion guidance: $MOTION_GUIDANCE (increased precision)"
        echo "Motion seed: $MOTION_SEED"
        echo "Duration: $DURATION seconds (extended for better motion flow)"
        echo "Resolution: $RESOLUTION (optimized for social media)"
        echo "FPS: $FPS (smooth motion)"
        echo "Model: $MODEL"
        echo "Using enhanced Deuce dancing motion prompt: $DANCING_MOTION_PROMPT"
        echo "Negative prompt: $RUNWAY_NEGATIVE_PROMPT"
        echo "Quality enhancers: Motion[$MOTION_DESCRIPTORS], Camera[$CAMERA_STABILITY], Dance[$DANCE_QUALITY]"
        
        # Run the enhanced RunwayML video generator
        python image_generator.py
        
        # Verify video was created
        echo "üìπ Checking generated videos..."
        if ls final_animation.mp4 1> /dev/null 2>&1; then
          echo "‚úÖ RunwayML Deuce dancing video generated successfully!"
          ls -la final_animation.mp4
        elif ls runwayml_generation_*.mp4 1> /dev/null 2>&1; then
          echo "‚úÖ RunwayML video files found!"
          ls -la runwayml_generation_*.mp4
        else
          echo "‚ö†Ô∏è No video files found, checking for fallback images..."
          ls -la *.jpg *.jpeg *.png 2>/dev/null || echo "‚ùå No files found!"
        fi

    # ENHANCED DEUCE ANIMATION SECTION (Fallback for non-RunwayML content)
    - name: Install Animation Dependencies
      run: |
        pip install opencv-python pillow numpy imageio imageio-ffmpeg
        echo "üé¨ Backup animation dependencies installed"

    - name: Create Enhanced Deuce Animation Script (Fallback)
      run: |
        cat > animate_image.py << 'EOF'
        import cv2
        import numpy as np
        from PIL import Image
        import os
        import imageio
        import glob

        def create_fallback_animation():
            """Create fallback animation if RunwayML didn't generate video"""
            print("üîÑ Creating fallback Deuce animation...")
            
            # Check if RunwayML already created final_animation.mp4
            if os.path.exists("final_animation.mp4"):
                print("‚úÖ RunwayML video already exists, skipping fallback")
                return True
            
            # Look for any generated images to animate
            image_patterns = ["dalle_generation_*.png", "*.png", "*.jpg"]
            
            image_files = []
            for pattern in image_patterns:
                found_files = glob.glob(pattern)
                if found_files:
                    image_files.extend(found_files)
                    break
            
            if not image_files:
                print("‚ùå No images found for fallback animation")
                return False
                
            print(f"üñºÔ∏è Creating fallback animation from: {image_files[0]}")
            
            # Create simple animation as backup
            img = cv2.imread(image_files[0])
            if img is None:
                return False
                
            height, width = img.shape[:2]
            target_width, target_height = 1080, 1920
            
            # Simple resize and save
            scale = min(target_width/width, target_height/height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            img_resized = cv2.resize(img, (new_width, new_height))
            
            # Create simple frames for longer duration
            frames = []
            for i in range(300):  # 10 seconds at 30fps (matching new duration)
                frame_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
                frames.append(frame_rgb)
            
            # Save fallback video
            imageio.mimsave("final_animation.mp4", frames, fps=30, quality=8)
            print("‚úÖ Fallback Deuce animation created")
            return True

        if __name__ == "__main__":
            create_fallback_animation()
        EOF

    - name: Generate Backup Animation (If Needed)
      env:
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || github.event.inputs.animation_type || 'dancing' }}
      run: |
        echo "üé¨ Checking if backup Deuce animation is needed..."
        
        if [ -f "final_animation.mp4" ]; then
          echo "‚úÖ RunwayML video exists, no backup needed"
          ls -lh final_animation.mp4
        else
          echo "üîÑ Running backup animation script..."
          python animate_image.py
        fi

    - name: Verify Video Output
      run: |
        if [ -f "final_animation.mp4" ]; then
          echo "‚úÖ Deuce video file ready for processing!"
          ls -lh final_animation.mp4
          
          # Install ffmpeg for video analysis
          sudo apt-get update && sudo apt-get install -y ffmpeg
          
          echo "üìπ Video information:"
          ffprobe -v quiet -print_format json -show_format -show_streams final_animation.mp4 | jq '.format.duration, .streams[0].width, .streams[0].height, .streams[0].avg_frame_rate'
        else
          echo "‚ùå No video file found!"
          echo "üìÅ Current directory contents:"
          ls -la
          exit 1
        fi

    # ADVANCED VIDEO POST-PRODUCTION
    - name: Install Video Processing Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg imagemagick fonts-dejavu-core
        
        # Install additional fonts for better text rendering
        sudo apt-get install -y fonts-liberation fonts-open-sans
        
        echo "üé¨ Video processing environment ready!"

    - name: Create Advanced RunwayML Deuce Video Editor Script
      run: |
       cat > advanced_video_editor.py << 'EOF'
import subprocess
import os
import json
import sys
import re
from pathlib import Path

class RunwayMLVideoProcessor:
    def __init__(self):
        self.video_file = "final_animation.mp4"
        self.audio_file = None
        self.recipe_text = ""
        self.output_file = "tiktok_masterpiece.mp4"
        
    def find_files(self):
        """Find all necessary files for video processing"""
        print("üîç Searching for RunwayML Deuce video and audio files...")
        
        # Find animated video
        if not os.path.exists(self.video_file):
            print("‚ùå Video not found!")
            return False
            
        # Check for voice audio (will be uploaded by n8n)
        audio_files = [f for f in os.listdir(".") if f.endswith(('.mp3', '.wav', '.m4a'))]
        if audio_files:
            self.audio_file = audio_files[0]
            print(f"üé§ Found audio: {self.audio_file}")
        else:
            print("‚ö†Ô∏è No audio file found, creating video without voice-over")
        
        print(f"üìπ Video: {self.video_file}")
        return True
        
    def get_recipe_text(self):
        """Extract recipe text for overlay"""
        # Get recipe text from GitHub Actions environment
        recipe_from_payload = os.environ.get('RECIPE_TEXT', '')
        animation_type = os.environ.get('ANIMATION_TYPE', 'dancing')
        selected_dance = os.environ.get('SELECTED_DANCE', 'macarena')
        
        if recipe_from_payload:
            self.recipe_text = recipe_from_payload
        else:
            # Generate cute Deuce text based on animation type and dance (NO EMOJIS)
            deuce_texts = {
                'emergence': "Deuce discovers amazing food! So precious!",
                'eating': "Watch Deuce enjoy delicious food! So adorable!",
                'dancing': f"Deuce does the {selected_dance.title()}! This little angel has the smoothest moves!"
            }
            self.recipe_text = deuce_texts.get(animation_type, f"Deuce's most adorable {selected_dance} dancing adventure!")
            
        print(f"üìù Video text: {self.recipe_text[:50]}...")
        
    def sanitize_text_for_ffmpeg(self, text):
        """Sanitize text for FFmpeg to avoid special character issues"""
        # Remove emojis and special characters that cause FFmpeg issues
        sanitized = re.sub(r'[^\w\s\-\!\?\.\,\']', '', text)
        # Replace single quotes with escaped quotes
        sanitized = sanitized.replace("'", "\\'")
        # Limit length
        if len(sanitized) > 100:
            sanitized = sanitized[:97] + "..."
        return sanitized
        
    def create_text_overlay(self):
        """Create stylized text overlay for TikTok"""
        # Sanitize the text first
        clean_text = self.sanitize_text_for_ffmpeg(self.recipe_text)
        
        # Split text into multiple lines for better readability
        words = clean_text.split()
        lines = []
        current_line = ""
        
        for word in words:
            if len(current_line + " " + word) <= 25:  # Shorter lines for mobile
                current_line += " " + word if current_line else word
            else:
                lines.append(current_line)
                current_line = word
                
        if current_line:
            lines.append(current_line)
        
        # Limit to 3 lines for mobile viewing
        formatted_text = "\\n".join(lines[:3])
        
        return formatted_text
        
    def create_professional_video(self):
        """Create professional-quality RunwayML enhanced video with simplified overlay"""
        print("üé¨ Creating professional RunwayML Deuce dancing video...")
        
        formatted_text = self.create_text_overlay()
        
        # Advanced FFmpeg command optimized for RunwayML content
        base_cmd = [
            'ffmpeg', '-y',
            '-i', self.video_file
        ]
        
        # Add audio if available
        if self.audio_file:
            base_cmd.extend(['-i', self.audio_file])
        
        # SIMPLIFIED filter complex to avoid text parsing issues
        filter_parts = []
        
        # Video scaling and enhancement for RunwayML content
        filter_parts.append(
            "[0:v]scale=1080:1920:force_original_aspect_ratio=decrease,"
            "pad=1080:1920:(ow-iw)/2:(oh-ih)/2:color=#FFF0F5@1.0,"
            "eq=brightness=0.05:contrast=1.1:saturation=1.15[scaled]"
        )
        
        # SIMPLIFIED text overlay without complex styling
        text_filter = (
            f"[scaled]drawtext="
            f"text='{formatted_text}':"
            f"fontsize=36:"
            f"fontcolor=white:"
            f"x=(w-text_w)/2:"
            f"y=h-180:"
            f"box=1:"
            f"boxcolor=black@0.8:"
            f"boxborderw=6[texted]"
        )
        filter_parts.append(text_filter)
        
        # Combine filters
        filter_complex = ";".join(filter_parts)
        
        base_cmd.extend([
            '-filter_complex', filter_complex,
            '-map', '[texted]'
        ])
        
        # Audio mapping
        if self.audio_file:
            base_cmd.extend(['-map', '1:a'])
            
        # Professional encoding settings optimized for social media
        base_cmd.extend([
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '18',  # Higher quality for RunwayML content
            '-c:a', 'aac',
            '-b:a', '128k',
            '-r', '30',
            '-shortest' if self.audio_file else '-t', '10',
            '-movflags', '+faststart',  # Optimize for web playback
            self.output_file
        ])
        
        try:
            print("üöÄ Executing enhanced RunwayML video processing...")
            print(f"üé¨ Using text overlay: {formatted_text}")
            
            result = subprocess.run(base_cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print("‚úÖ Professional RunwayML Deuce dancing video created successfully!")
                self.analyze_output()
                return True
            else:
                print(f"‚ùå FFmpeg error: {result.stderr}")
                # Try creating video without text overlay as fallback
                return self.create_simple_video()
                
        except subprocess.TimeoutExpired:
            print("‚ùå Video processing timed out")
            return False
        except Exception as e:
            print(f"‚ùå Unexpected error: {e}")
            return False
    
    def create_simple_video(self):
        """Fallback: Create video without text overlay"""
        print("üîÑ Creating simplified video without text overlay...")
        
        base_cmd = [
            'ffmpeg', '-y',
            '-i', self.video_file,
            '-vf', 'scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2:color=#FFF0F5@1.0',
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '18',
            '-r', '30',
            '-t', '10',
            '-movflags', '+faststart',
            self.output_file
        ]
        
        try:
            result = subprocess.run(base_cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print("‚úÖ Simplified RunwayML Deuce dancing video created successfully!")
                self.analyze_output()
                return True
            else:
                print(f"‚ùå Simplified video creation also failed: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"‚ùå Simplified video creation failed: {e}")
            return False
            
    def analyze_output(self):
        """Analyze the created video"""
        if not os.path.exists(self.output_file):
            return
            
        # Get video info
        info_cmd = [
            'ffprobe', '-v', 'quiet', '-print_format', 'json',
            '-show_format', '-show_streams', self.output_file
        ]
        
        try:
            result = subprocess.run(info_cmd, capture_output=True, text=True)
            if result.returncode == 0:
                info = json.loads(result.stdout)
                duration = float(info['format']['duration'])
                size_mb = os.path.getsize(self.output_file) / (1024*1024)
                
                print(f"üìä Enhanced RunwayML Deuce Dancing Video Analysis:")
                print(f"   Duration: {duration:.1f} seconds")
                print(f"   File Size: {size_mb:.1f} MB")
                print(f"   Format: MP4 (1080x1920)")
                print(f"   Quality: Professional grade with enhanced motion")
                print(f"   Status: Ready for viral success! üé¨‚ú®")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Could not analyze video: {e}")
            
    def process_video(self):
        """Main processing pipeline"""
        print("üé¨ STARTING ENHANCED RUNWAYML DEUCE DANCING VIDEO PROCESSING PIPELINE")
        print("=" * 50)
        
        if not self.find_files():
            return False
            
        self.get_recipe_text()
        
        success = self.create_professional_video()
        
        if success:
            print("üéâ ENHANCED RUNWAYML DEUCE DANCING MASTERPIECE CREATED!")
            print(f"üì± File: {self.output_file}")
            return True
        else:
            print("‚ùå Video processing failed")
            return False

# Execute the video processor
if __name__ == "__main__":
    processor = RunwayMLVideoProcessor()
    success = processor.process_video()
    sys.exit(0 if success else 1)
EOF
    - name: Execute Advanced RunwayML Video Processing
      env:
        RECIPE_TEXT: ${{ github.event.client_payload.recipe_text }}
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || 'dancing' }}
        SELECTED_DANCE: ${{ github.event.client_payload.selected_dance || 'macarena' }}
      run: |
        echo "üé¨ Launching enhanced RunwayML Deuce dancing video processing..."
        python3 advanced_video_editor.py

    - name: Upload generated videos
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: runwayml-deuce-dancing-videos
        path: |
          runwayml_generation_*.mp4
          final_animation.mp4
          reference_video.*
        retention-days: 30

    - name: Upload RunwayML Deuce Dancing Masterpiece
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: deuce-dancing-tiktok-masterpiece
        path: |
          tiktok_masterpiece.mp4
          final_animation.mp4
          reference_video.*
          *.mp3
          *.wav
        retention-days: 30

    - name: Create Epic RunwayML Deuce Dancing Summary
      if: always()
      run: |
        echo "## üï∫ ENHANCED RUNWAYML DEUCE DANCING MASTERPIECE GENERATED! ‚ú®" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üöÄ Your Professional AI Dancing Video Package (Enhanced with Video Reference):" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "tiktok_masterpiece.mp4" ]; then
          VIDEO_SIZE=$(du -h tiktok_masterpiece.mp4 | cut -f1)
          ANIMATION_TYPE="${{ github.event.client_payload.animation_type || 'dancing' }}"
          SELECTED_DANCE="${{ github.event.client_payload.selected_dance || 'macarena' }}"
          USE_VIDEO_REF="${{ github.event.client_payload.use_video_reference || 'false' }}"
          echo "- üé• **Enhanced RunwayML Deuce Dancing Video:** tiktok_masterpiece.mp4 ($VIDEO_SIZE)" >> $GITHUB_STEP_SUMMARY
          echo "- ü§ñ **AI Technology:** RunwayML Gen-3a with Enhanced Motion Quality" >> $GITHUB_STEP_SUMMARY
          echo "- üíÉ **Dance Type:** $SELECTED_DANCE (Reference-guided)" >> $GITHUB_STEP_SUMMARY
          echo "- üé¨ **Generation Mode:** $( [[ "$USE_VIDEO_REF" == "true" ]] && echo "Video-to-Video (Reference-based)" || echo "Text-to-Video" )" >> $GITHUB_STEP_SUMMARY
          echo "- üéØ **Camera Control:** Static positioning with enhanced stability" >> $GITHUB_STEP_SUMMARY
          echo "- üï∫ **Star:** Deuce the Shih Tzu with smooth fluid human-like $SELECTED_DANCE dancing" >> $GITHUB_STEP_SUMMARY
          echo "- üì± **Format:** 1080x1920 (Perfect 9:16 optimized)" >> $GITHUB_STEP_SUMMARY
          echo "- ‚è±Ô∏è **Duration:** Extended 10-second professional videos" >> $GITHUB_STEP_SUMMARY
          echo "- üé¨ **Quality:** Cinema-grade AI animation with motion enhancements" >> $GITHUB_STEP_SUMMARY
          echo "- üé® **Movement:** Enhanced human-like dancing with professional choreography" >> $GITHUB_STEP_SUMMARY
          echo "- ‚ö° **Motion Settings:** Strength: ${{ github.event.client_payload.runway_settings.motion_strength || '6' }}, Guidance: ${{ github.event.client_payload.runway_settings.motion_guidance || '12' }}" >> $GITHUB_STEP_SUMMARY
          echo "- üéØ **FPS:** ${{ github.event.client_payload.runway_settings.fps || '30' }} fps for ultra-smooth motion" >> $GITHUB_STEP_SUMMARY
          
          if [[ "$USE_VIDEO_REF" == "true" ]]; then
            echo "- üì∫ **Reference Video:** Used for precise $SELECTED_DANCE choreography" >> $GITHUB_STEP_SUMMARY
            echo "- üéØ **Reference Strength:** ${{ github.event.client_payload.runway_settings.reference_strength || '0.8' }}" >> $GITHUB_STEP_SUMMARY
          fi
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üéØ Ready for Viral Success with Enhanced Quality!" >> $GITHUB_STEP_SUMMARY
        echo "Your enhanced professional RunwayML Deuce dancing content features:" >> $GITHUB_STEP_SUMMARY
        echo "- ‚ú® Smooth fluid motion with seamless transitions" >> $GITHUB_STEP_SUMMARY
        echo "- üé≠ Professional choreography-style movements" >> $GITHUB_STEP_SUMMARY
        echo "- üì∑ Static camera with enhanced stability controls" >> $GITHUB_STEP_SUMMARY
        echo "- üé® Photorealistic quality with cinematic lighting" >> $GITHUB_STEP_SUMMARY
        echo "- üéµ Rhythmic tempo matching for perfect dance synchronization" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ github.event.client_payload.use_video_reference }}" == "true" ]]; then
          echo "- üé• **Reference-guided precision:** Exact ${{ github.event.client_payload.selected_dance || 'macarena' }} choreography" >> $GITHUB_STEP_SUMMARY
          echo "- üíÉ **Motion accuracy:** Video-to-video generation for realistic moves" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Optimized for platforms:** TikTok ‚Ä¢ YouTube Shorts ‚Ä¢ Instagram Reels" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**üï∫ DEUCE DANCING LEVEL: PROFESSIONAL ENHANCED WITH VIDEO REFERENCE ‚ú®**" >> $GITHUB_STEP_SUMMARY

    - name: Job completed
      if: always()
      run: echo "‚úÖ Ultimate Enhanced RunwayML Deuce Human-Like Dancing Content Creation mission completed! üï∫üêï‚ú®"
