name: "Ultimate RunwayML Deuce Dancing Generator"
on:
  repository_dispatch:
    types: [trigger-midjourney, create-masterpiece, trigger-shih-tzu-food-video]
  workflow_dispatch:
    inputs:
      prompt:
        description: 'Image generation prompt'
        required: true
        default: 'Deuce the adorable Shih Tzu dancing like a human next to delicious trending food dish'
      animation_type:
        description: 'Animation type (dancing, eating, emergence)'
        required: false
        default: 'dancing'
jobs:
  runwayml-deuce-generator:
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up job
      run: echo "ğŸ¬ Starting Ultimate RunwayML Deuce Human-Like Dancing mission"
      
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Clean Previous Files
      run: |
        echo "ğŸ§¹ Cleaning previous images and artifacts..."
        rm -f dalle_generation_*.png
        rm -f runwayml_generation_*.mp4
        rm -f dalle_generation_*.jpg
        rm -f *.png
        rm -f *.jpg
        rm -f final_animation.mp4
        rm -f *.mp4
        rm -f *.mp3
        rm -f *.wav
        echo "âœ… Previous files cleared"
        echo "ğŸ“ Current directory after cleanup:"
        ls -la
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        # Update pip and install from requirements
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        echo "ğŸ“¦ Installed packages:"
        pip list

    - name: Debug Enhanced Deuce Dancing Payload
      env:
        PROMPT: ${{ github.event.client_payload.runway_prompt || github.event.client_payload.prompt || github.event.inputs.prompt || 'Deuce the adorable Shih Tzu dancing like a human next to delicious trending food dish' }}
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || github.event.inputs.animation_type || 'dancing' }}
        DANCING_MOTION_PROMPT: ${{ github.event.client_payload.dancing_motion_prompt }}
        RUNWAY_NEGATIVE_PROMPT: ${{ github.event.client_payload.runway_negative_prompt }}
        CAMERA_MOTION: ${{ github.event.client_payload.runway_motion_settings.camera_motion || '0' }}
        MOTION_STRENGTH: ${{ github.event.client_payload.runway_motion_settings.motion_strength || '4' }}
        MOTION_GUIDANCE: ${{ github.event.client_payload.runway_motion_settings.motion_guidance || '9' }}
        DURATION: ${{ github.event.client_payload.runway_generation_params.duration || '5' }}
        RUNWAYML_API_KEY: ${{ secrets.RUNWAYML_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        echo "ğŸ” Debug: Enhanced Deuce Dancing Parameters..."
        echo "Primary prompt: $PROMPT"
        echo "Deuce dancing motion prompt: $DANCING_MOTION_PROMPT"
        echo "Negative prompt: $RUNWAY_NEGATIVE_PROMPT"
        echo "Camera motion: $CAMERA_MOTION (0 = static)"
        echo "Motion strength: $MOTION_STRENGTH"
        echo "Motion guidance: $MOTION_GUIDANCE"
        echo "Duration: $DURATION seconds"
        echo "Animation type: $ANIMATION_TYPE"
        echo "RunwayML API key configured: $([[ -n "$RUNWAYML_API_KEY" ]] && echo "âœ… Yes" || echo "âŒ No")"
        
    - name: Run Enhanced RunwayML Deuce Dancing Video Generator
      env:
        # Primary prompt settings
        PROMPT: ${{ github.event.client_payload.runway_prompt || github.event.client_payload.prompt || github.event.inputs.prompt || 'Deuce the adorable Shih Tzu dancing like a human next to delicious trending food dish' }}
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || github.event.inputs.animation_type || 'dancing' }}
        
        # Deuce dancing-specific motion settings for camera control
        DANCING_MOTION_PROMPT: ${{ github.event.client_payload.dancing_motion_prompt }}
        RUNWAY_NEGATIVE_PROMPT: ${{ github.event.client_payload.runway_negative_prompt }}
        CAMERA_MOTION: ${{ github.event.client_payload.runway_motion_settings.camera_motion || '0' }}
        MOTION_STRENGTH: ${{ github.event.client_payload.runway_motion_settings.motion_strength || '4' }}
        MOTION_GUIDANCE: ${{ github.event.client_payload.runway_motion_settings.motion_guidance || '9' }}
        MOTION_SEED: ${{ github.event.client_payload.runway_motion_settings.seed }}
        UPSCALE: ${{ github.event.client_payload.runway_motion_settings.upscale || 'true' }}
        
        # Generation parameters
        DURATION: ${{ github.event.client_payload.runway_generation_params.duration || '5' }}
        FPS: ${{ github.event.client_payload.runway_generation_params.fps || '24' }}
        RESOLUTION: ${{ github.event.client_payload.runway_generation_params.resolution || '1280x768' }}
        MODEL: ${{ github.event.client_payload.runway_generation_params.model || 'gen3a_turbo' }}
        
        # Motion brush settings for human-like dancing effect
        SUBJECT_AREA: ${{ github.event.client_payload.runway_motion_brush.subject_area || 'deuce_shih_tzu_character' }}
        MOTION_TYPE: ${{ github.event.client_payload.runway_motion_brush.motion_type || 'human_like_dancing_movement' }}
        MOTION_DIRECTION: ${{ github.event.client_payload.runway_motion_brush.motion_direction || 'upright_anthropomorphic_dancing' }}
        MOTION_INTENSITY: ${{ github.event.client_payload.runway_motion_brush.motion_intensity || 'medium_bouncy_human_like' }}
        STATIC_AREAS: ${{ github.event.client_payload.runway_motion_brush.static_areas || 'background_plate_edges' }}
        
        # API keys
        RUNWAYML_API_KEY: ${{ secrets.RUNWAYML_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        N8N_WEBHOOK: ${{ secrets.N8N_WEBHOOK }}
      run: |
        echo "ğŸ¬ Generating REAL animated Deuce dancing video with RunwayML..."
        echo "ğŸ•º Human-like dancing animation with STATIC camera"
        echo "Animation type: $ANIMATION_TYPE"
        echo "Camera motion: $CAMERA_MOTION (0 = completely static)"
        echo "Using Deuce dancing motion prompt: $DANCING_MOTION_PROMPT"
        echo "Negative prompt: $RUNWAY_NEGATIVE_PROMPT"
        
        # Run the enhanced RunwayML video generator
        python image_generator.py
        
        # Verify video was created
        echo "ğŸ“¹ Checking generated videos..."
        if ls final_animation.mp4 1> /dev/null 2>&1; then
          echo "âœ… RunwayML Deuce dancing video generated successfully!"
          ls -la final_animation.mp4
        elif ls runwayml_generation_*.mp4 1> /dev/null 2>&1; then
          echo "âœ… RunwayML video files found!"
          ls -la runwayml_generation_*.mp4
        else
          echo "âš ï¸ No video files found, checking for fallback images..."
          ls -la *.jpg *.jpeg *.png 2>/dev/null || echo "âŒ No files found!"
        fi

    # ENHANCED DEUCE ANIMATION SECTION (Fallback for non-RunwayML content)
    - name: Install Animation Dependencies
      run: |
        pip install opencv-python pillow numpy imageio imageio-ffmpeg
        echo "ğŸ¬ Backup animation dependencies installed"

    - name: Create Enhanced Deuce Animation Script (Fallback)
      run: |
        cat > animate_image.py << 'EOF'
        import cv2
        import numpy as np
        from PIL import Image
        import os
        import imageio
        import glob

        def create_fallback_animation():
            """Create fallback animation if RunwayML didn't generate video"""
            print("ğŸ”„ Creating fallback Deuce animation...")
            
            # Check if RunwayML already created final_animation.mp4
            if os.path.exists("final_animation.mp4"):
                print("âœ… RunwayML video already exists, skipping fallback")
                return True
            
            # Look for any generated images to animate
            image_patterns = ["dalle_generation_*.png", "*.png", "*.jpg"]
            
            image_files = []
            for pattern in image_patterns:
                found_files = glob.glob(pattern)
                if found_files:
                    image_files.extend(found_files)
                    break
            
            if not image_files:
                print("âŒ No images found for fallback animation")
                return False
                
            print(f"ğŸ–¼ï¸ Creating fallback animation from: {image_files[0]}")
            
            # Create simple animation as backup
            img = cv2.imread(image_files[0])
            if img is None:
                return False
                
            height, width = img.shape[:2]
            target_width, target_height = 1080, 1920
            
            # Simple resize and save
            scale = min(target_width/width, target_height/height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            img_resized = cv2.resize(img, (new_width, new_height))
            
            # Create simple frames
            frames = []
            for i in range(150):  # 5 seconds at 30fps
                frame_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
                frames.append(frame_rgb)
            
            # Save fallback video
            imageio.mimsave("final_animation.mp4", frames, fps=30, quality=8)
            print("âœ… Fallback Deuce animation created")
            return True

        if __name__ == "__main__":
            create_fallback_animation()
        EOF

    - name: Generate Backup Animation (If Needed)
      env:
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || github.event.inputs.animation_type || 'dancing' }}
      run: |
        echo "ğŸ¬ Checking if backup Deuce animation is needed..."
        
        if [ -f "final_animation.mp4" ]; then
          echo "âœ… RunwayML video exists, no backup needed"
          ls -lh final_animation.mp4
        else
          echo "ğŸ”„ Running backup animation script..."
          python animate_image.py
        fi

    - name: Verify Video Output
      run: |
        if [ -f "final_animation.mp4" ]; then
          echo "âœ… Deuce video file ready for processing!"
          ls -lh final_animation.mp4
          
          # Install ffmpeg for video analysis
          sudo apt-get update && sudo apt-get install -y ffmpeg
          
          echo "ğŸ“¹ Video information:"
          ffprobe -v quiet -print_format json -show_format -show_streams final_animation.mp4 | jq '.format.duration, .streams[0].width, .streams[0].height, .streams[0].avg_frame_rate'
        else
          echo "âŒ No video file found!"
          echo "ğŸ“ Current directory contents:"
          ls -la
          exit 1
        fi

    # ADVANCED VIDEO POST-PRODUCTION
    - name: Install Video Processing Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg imagemagick fonts-dejavu-core
        
        # Install additional fonts for better text rendering
        sudo apt-get install -y fonts-liberation fonts-open-sans
        
        echo "ğŸ¬ Video processing environment ready!"

    - name: Create Advanced RunwayML Deuce Video Editor Script
      run: |
        cat > advanced_video_editor.py << 'EOF'
        import subprocess
        import os
        import json
        import sys
        from pathlib import Path

        class RunwayMLVideoProcessor:
            def __init__(self):
                self.video_file = "final_animation.mp4"
                self.audio_file = None
                self.recipe_text = ""
                self.output_file = "tiktok_masterpiece.mp4"
                
            def find_files(self):
                """Find all necessary files for video processing"""
                print("ğŸ” Searching for RunwayML Deuce video and audio files...")
                
                # Find animated video
                if not os.path.exists(self.video_file):
                    print("âŒ Video not found!")
                    return False
                    
                # Check for voice audio (will be uploaded by n8n)
                audio_files = [f for f in os.listdir(".") if f.endswith(('.mp3', '.wav', '.m4a'))]
                if audio_files:
                    self.audio_file = audio_files[0]
                    print(f"ğŸ¤ Found audio: {self.audio_file}")
                else:
                    print("âš ï¸ No audio file found, creating video without voice-over")
                
                print(f"ğŸ“¹ Video: {self.video_file}")
                return True
                
            def get_recipe_text(self):
                """Extract recipe text for overlay"""
                # Get recipe text from GitHub Actions environment
                recipe_from_payload = os.environ.get('RECIPE_TEXT', '')
                animation_type = os.environ.get('ANIMATION_TYPE', 'dancing')
                
                if recipe_from_payload:
                    self.recipe_text = recipe_from_payload
                else:
                    # Generate cute Deuce text based on animation type
                    deuce_texts = {
                        'emergence': "âœ¨ Deuce discovers amazing food! So precious! ğŸ•ğŸ’«",
                        'eating': "ğŸ˜‹ Watch Deuce enjoy delicious food! So adorable! ğŸ½ï¸â¤ï¸",
                        'dancing': "ğŸµ Deuce dances like a human! This little angel has the best moves! ğŸ’ƒğŸ•"
                    }
                    self.recipe_text = deuce_texts.get(animation_type, "ğŸ• Deuce's most adorable human-like dancing adventure! âœ¨")
                    
                print(f"ğŸ“ Video text: {self.recipe_text[:50]}...")
                
            def create_text_overlay(self):
                """Create stylized text overlay for TikTok"""
                # Split text into multiple lines for better readability
                words = self.recipe_text.split()
                lines = []
                current_line = ""
                
                for word in words:
                    if len(current_line + " " + word) <= 25:  # Shorter lines for mobile
                        current_line += " " + word if current_line else word
                    else:
                        lines.append(current_line)
                        current_line = word
                        
                if current_line:
                    lines.append(current_line)
                
                # Limit to 3 lines for mobile viewing
                formatted_text = "\\n".join(lines[:3])
                
                return formatted_text
                
            def create_professional_video(self):
                """Create professional-quality RunwayML enhanced video"""
                print("ğŸ¬ Creating professional RunwayML Deuce dancing video...")
                
                formatted_text = self.create_text_overlay()
                
                # Advanced FFmpeg command optimized for RunwayML content
                base_cmd = [
                    'ffmpeg', '-y',
                    '-i', self.video_file
                ]
                
                # Add audio if available
                if self.audio_file:
                    base_cmd.extend(['-i', self.audio_file])
                
                # Create sophisticated filter complex for RunwayML content
                filter_parts = []
                
                # Video scaling and enhancement for RunwayML content
                filter_parts.append(
                    "[0:v]scale=1080:1920:force_original_aspect_ratio=decrease,"
                    "pad=1080:1920:(ow-iw)/2:(oh-ih)/2:color=#FFF0F5@1.0,"  # Light pink background
                    "eq=brightness=0.05:contrast=1.1:saturation=1.15[scaled]"  # Enhance RunwayML output
                )
                
                # Subtle text overlay that doesn't interfere with RunwayML animation
                text_filter = (
                    f"[scaled]drawtext="
                    f"text='{formatted_text}':"
                    f"fontfile=/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf:"
                    f"fontsize=38:"
                    f"fontcolor=white:"
                    f"x=(w-text_w)/2:"
                    f"y=h-200:"
                    f"box=1:"
                    f"boxcolor=#FF69B4@0.7:"  # Semi-transparent pink box
                    f"boxborderw=8:"
                    f"shadowcolor=black@0.6:"
                    f"shadowx=2:"
                    f"shadowy=2[texted]"
                )
                filter_parts.append(text_filter)
                
                # Combine filters
                filter_complex = ";".join(filter_parts)
                
                base_cmd.extend([
                    '-filter_complex', filter_complex,
                    '-map', '[texted]'
                ])
                
                # Audio mapping
                if self.audio_file:
                    base_cmd.extend(['-map', '1:a'])
                    
                # Professional encoding settings optimized for social media
                base_cmd.extend([
                    '-c:v', 'libx264',
                    '-preset', 'medium',
                    '-crf', '18',  # Higher quality for RunwayML content
                    '-c:a', 'aac',
                    '-b:a', '128k',
                    '-r', '30',
                    '-shortest' if self.audio_file else '-t', '8',
                    '-movflags', '+faststart',  # Optimize for web playback
                    self.output_file
                ])
                
                try:
                    print("ğŸš€ Executing RunwayML video enhancement...")
                    result = subprocess.run(base_cmd, capture_output=True, text=True, timeout=300)
                    
                    if result.returncode == 0:
                        print("âœ… Professional RunwayML Deuce dancing video created successfully!")
                        self.analyze_output()
                        return True
                    else:
                        print(f"âŒ FFmpeg error: {result.stderr}")
                        return False
                        
                except subprocess.TimeoutExpired:
                    print("âŒ Video processing timed out")
                    return False
                except Exception as e:
                    print(f"âŒ Unexpected error: {e}")
                    return False
                    
            def analyze_output(self):
                """Analyze the created video"""
                if not os.path.exists(self.output_file):
                    return
                    
                # Get video info
                info_cmd = [
                    'ffprobe', '-v', 'quiet', '-print_format', 'json',
                    '-show_format', '-show_streams', self.output_file
                ]
                
                try:
                    result = subprocess.run(info_cmd, capture_output=True, text=True)
                    if result.returncode == 0:
                        info = json.loads(result.stdout)
                        duration = float(info['format']['duration'])
                        size_mb = os.path.getsize(self.output_file) / (1024*1024)
                        
                        print(f"ğŸ“Š RunwayML Deuce Dancing Video Analysis:")
                        print(f"   Duration: {duration:.1f} seconds")
                        print(f"   File Size: {size_mb:.1f} MB")
                        print(f"   Format: MP4 (1080x1920)")
                        print(f"   Status: Ready for viral success! ğŸ¬âœ¨")
                        
                except Exception as e:
                    print(f"âš ï¸ Could not analyze video: {e}")
                    
            def process_video(self):
                """Main processing pipeline"""
                print("ğŸ¬ STARTING RUNWAYML DEUCE DANCING VIDEO PROCESSING PIPELINE")
                print("=" * 50)
                
                if not self.find_files():
                    return False
                    
                self.get_recipe_text()
                
                success = self.create_professional_video()
                
                if success:
                    print("ğŸ‰ RUNWAYML DEUCE DANCING MASTERPIECE CREATED!")
                    print(f"ğŸ“± File: {self.output_file}")
                    return True
                else:
                    print("âŒ Video processing failed")
                    return False

        # Execute the video processor
        if __name__ == "__main__":
            processor = RunwayMLVideoProcessor()
            success = processor.process_video()
            sys.exit(0 if success else 1)
        EOF

    - name: Execute Advanced RunwayML Video Processing
      env:
        RECIPE_TEXT: ${{ github.event.client_payload.recipe_text }}
        ANIMATION_TYPE: ${{ github.event.client_payload.animation_type || 'dancing' }}
      run: |
        echo "ğŸ¬ Launching advanced RunwayML Deuce dancing video processing..."
        python3 advanced_video_editor.py

    - name: Upload generated videos
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: runwayml-deuce-dancing-videos
        path: |
          runwayml_generation_*.mp4
          final_animation.mp4
        retention-days: 30

    - name: Upload RunwayML Deuce Dancing Masterpiece
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: deuce-dancing-tiktok-masterpiece
        path: |
          tiktok_masterpiece.mp4
          final_animation.mp4
          *.mp3
          *.wav
        retention-days: 30

    - name: Create Epic RunwayML Deuce Dancing Summary
      if: always()
      run: |
        echo "## ğŸ•º RUNWAYML DEUCE DANCING MASTERPIECE GENERATED! âœ¨" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ğŸš€ Your Professional AI Dancing Video Package:" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "tiktok_masterpiece.mp4" ]; then
          VIDEO_SIZE=$(du -h tiktok_masterpiece.mp4 | cut -f1)
          ANIMATION_TYPE="${{ github.event.client_payload.animation_type || 'dancing' }}"
          echo "- ğŸ¥ **RunwayML Deuce Dancing Video:** tiktok_masterpiece.mp4 ($VIDEO_SIZE)" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸ¤– **AI Technology:** RunwayML Gen-3a Turbo (Real Animation)" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸ¯ **Camera Control:** Static positioning (no drift)" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸ•º **Star:** Deuce the Shih Tzu dancing like a human with centered framing" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸ“± **Format:** 1080x1920 (Perfect 9:16)" >> $GITHUB_STEP_SUMMARY
          echo "- â±ï¸ **Duration:** Professional 5-second videos" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸ¬ **Quality:** Cinema-grade AI animation" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸ¨ **Movement:** Human-like upright dancing with arm movements" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ğŸ¯ Ready for Viral Success!" >> $GITHUB_STEP_SUMMARY
        echo "Your professional RunwayML Deuce dancing content is optimized for:" >> $GITHUB_STEP_SUMMARY
        echo "- TikTok (AI-powered viral dance potential)" >> $GITHUB_STEP_SUMMARY
        echo "- YouTube Shorts (premium dancing quality)" >> $GITHUB_STEP_SUMMARY
        echo "- Instagram Reels (cinema-grade dance content)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**ğŸ•º DEUCE DANCING LEVEL: PROFESSIONAL âœ¨**" >> $GITHUB_STEP_SUMMARY

    - name: Job completed
      if: always()
      run: echo "âœ… Ultimate RunwayML Deuce Human-Like Dancing Content Creation mission completed! ğŸ•ºğŸ•âœ¨"
