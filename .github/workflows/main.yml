name: "Ultimate Image Generator Automation"
on:
  repository_dispatch:
    types: [trigger-midjourney, create-masterpiece, trigger-shih-tzu-food-video]
  workflow_dispatch:
    inputs:
      prompt:
        description: 'Image generation prompt'
        required: true
        default: 'beautiful anime fitness girl doing morning yoga'
jobs:
  image-generator:
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up job
      run: echo "ðŸš€ Starting Ultimate Image Generator mission"
      
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Clean Previous Images
      run: |
        echo "ðŸ§¹ Cleaning previous images and artifacts..."
        rm -f dalle_generation_*.png
        rm -f dalle_generation_*.jpg
        rm -f *.png
        rm -f *.jpg
        rm -f final_animation.mp4
        rm -f *.mp4
        rm -f *.mp3
        rm -f *.wav
        echo "âœ… Previous images and videos cleared"
        echo "ðŸ“ Current directory after cleanup:"
        ls -la
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        # Update pip and install from requirements
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        echo "ðŸ“¦ Installed packages:"
        pip list

    - name: Debug Prompt Input
      env:
        PROMPT: ${{ github.event.client_payload.prompt || github.event.inputs.prompt || 'beautiful anime fitness girl doing morning yoga' }}
      run: |
        echo "ðŸ” Debug: Checking prompt input..."
        echo "Repository dispatch prompt: ${{ github.event.client_payload.prompt }}"
        echo "Manual input prompt: ${{ github.event.inputs.prompt }}"
        echo "Final PROMPT environment variable: $PROMPT"
        echo "Prompt length: ${#PROMPT}"
        
    - name: Run Ultimate Image Generator
      env:
        PROMPT: ${{ github.event.client_payload.prompt || github.event.inputs.prompt || 'beautiful anime fitness girl doing morning yoga' }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        N8N_WEBHOOK: ${{ secrets.N8N_WEBHOOK }}
      run: |
        echo "ðŸŽ¨ Generating image with prompt: $PROMPT"
        # Run the ultimate DALL-E image generator
        python image_generator.py
        
        # Verify image was created
        echo "ðŸ“¸ Checking generated images..."
        if ls dalle_generation_*.png 1> /dev/null 2>&1; then
          echo "âœ… New image generated successfully!"
          ls -la dalle_generation_*.png
        else
          echo "âš ï¸ No PNG files found, checking for other formats..."
          ls -la *.jpg *.jpeg 2>/dev/null || echo "âŒ No image files found!"
        fi

    # ANIMATION SECTION
    - name: Install Animation Dependencies
      run: |
        pip install opencv-python pillow numpy imageio imageio-ffmpeg
        echo "ðŸŽ¬ Animation dependencies installed"

    - name: Create Animation Script
      run: |
        cat > animate_image.py << 'EOF'
        import cv2
        import numpy as np
        from PIL import Image
        import os
        from pathlib import Path
        import imageio
        import glob

        def create_social_media_animation(image_path, output_path="final_animation.mp4"):
            """
            Create an engaging animation from DALL-E generated image for social media
            """
            print(f"ðŸŽ¬ Creating animation from: {image_path}")
            
            # Load the image
            img = cv2.imread(image_path)
            if img is None:
                print(f"âŒ Could not load image: {image_path}")
                return False
                
            height, width = img.shape[:2]
            print(f"ðŸ“ Original image size: {width}x{height}")
            
            # Social media format (9:16 aspect ratio for TikTok/YouTube Shorts)
            target_width = 1080
            target_height = 1920
            
            # Calculate scaling to fit within target dimensions
            scale = min(target_width/width, target_height/height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            
            # Resize image
            img_resized = cv2.resize(img, (new_width, new_height))
            
            # Create canvas with target dimensions (black background)
            canvas = np.zeros((target_height, target_width, 3), dtype=np.uint8)
            
            # Center the image on canvas
            y_offset = (target_height - new_height) // 2
            x_offset = (target_width - new_width) // 2
            canvas[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = img_resized
            
            # Animation parameters
            fps = 30
            duration = 8  # seconds - perfect for social media
            total_frames = fps * duration
            frames = []
            
            print(f"ðŸŽ­ Creating {total_frames} frames for {duration} second animation...")
            
            for frame_num in range(total_frames):
                progress = frame_num / total_frames
                
                # Multiple animation effects for engaging content
                
                # Effect 1: Gentle breathing/pulsing
                pulse = 1.0 + np.sin(progress * 6 * np.pi) * 0.03  # Subtle pulse
                
                # Effect 2: Slow rotation for dynamic feel
                angle = np.sin(progress * 2 * np.pi) * 1.5  # Gentle sway
                
                # Effect 3: Slow zoom for cinematic effect
                zoom = 1.0 + np.sin(progress * np.pi) * 0.05  # Slow zoom in/out
                
                # Combine effects
                scale_factor = pulse * zoom
                
                # Get transformation matrix
                center = (target_width // 2, target_height // 2)
                rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale_factor)
                
                # Apply transformation
                frame = cv2.warpAffine(canvas, rotation_matrix, (target_width, target_height))
                
                # Effect 4: Subtle color enhancement for food photography
                # Enhance saturation for more vibrant food colors
                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                hsv[:, :, 1] = cv2.multiply(hsv[:, :, 1], 1.15)  # Increase saturation for food
                frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
                
                # Convert BGR to RGB for imageio
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frames.append(frame_rgb)
                
                if frame_num % 60 == 0:
                    print(f"â³ Generated frame {frame_num}/{total_frames}")
            
            # Save as high-quality MP4
            print("ðŸ’¾ Saving animation...")
            imageio.mimsave(output_path, frames, fps=fps, quality=9, macro_block_size=1)
            print(f"âœ… Animation saved as {output_path}")
            
            return True

        def main():
            print("ðŸ” Looking for DALL-E generated images...")
            
            # Find DALL-E generated images
            image_patterns = [
                "dalle_generation_*.png",
                "dalle_generation_*.jpg",
                "*.png",
                "*.jpg"
            ]
            
            image_files = []
            for pattern in image_patterns:
                found_files = glob.glob(pattern)
                if found_files:
                    image_files.extend(found_files)
                    break
            
            if not image_files:
                print("âŒ No image files found!")
                print("ðŸ“ Current directory contents:")
                for item in os.listdir("."):
                    print(f"  - {item}")
                return False
                
            # Use the first (most recent) image
            image_path = image_files[0]
            print(f"ðŸ–¼ï¸  Using image: {image_path}")
            
            # Create animation
            success = create_social_media_animation(image_path)
            
            if success:
                print("ðŸŽ‰ Animation created successfully!")
                # Check file size
                if os.path.exists("final_animation.mp4"):
                    size = os.path.getsize("final_animation.mp4") / (1024*1024)
                    print(f"ðŸ“Š Final animation size: {size:.2f} MB")
                    print("ðŸš€ Ready for TikTok and YouTube Shorts!")
            else:
                print("âŒ Failed to create animation")
                
            return success

        if __name__ == "__main__":
            main()
        EOF

    - name: Generate Animation
      run: |
        echo "ðŸŽ¬ Starting animation generation..."
        python animate_image.py

    - name: Verify Animation Output
      run: |
        if [ -f "final_animation.mp4" ]; then
          echo "âœ… Animation file created successfully!"
          ls -lh final_animation.mp4
          
          # Install ffmpeg for video analysis
          sudo apt-get update && sudo apt-get install -y ffmpeg
          
          echo "ðŸ“¹ Video information:"
          ffprobe -v quiet -print_format json -show_format -show_streams final_animation.mp4 | jq '.format.duration, .streams[0].width, .streams[0].height, .streams[0].avg_frame_rate'
        else
          echo "âŒ Animation file not found!"
          echo "ðŸ“ Current directory contents:"
          ls -la
          exit 1
        fi

    # ADVANCED VIDEO POST-PRODUCTION
    - name: Install Video Processing Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg imagemagick fonts-dejavu-core
        
        # Install additional fonts for better text rendering
        sudo apt-get install -y fonts-liberation fonts-open-sans
        
        echo "ðŸŽ¬ Video processing environment ready!"

    - name: Create Advanced Video Editor Script
      run: |
        cat > advanced_video_editor.py << 'EOF'
        import subprocess
        import os
        import json
        import sys
        from pathlib import Path

        class TikTokVideoProcessor:
            def __init__(self):
                self.video_file = "final_animation.mp4"
                self.audio_file = None
                self.recipe_text = ""
                self.output_file = "tiktok_masterpiece.mp4"
                
            def find_files(self):
                """Find all necessary files for video processing"""
                print("ðŸ” Searching for video and audio files...")
                
                # Find animated video
                if not os.path.exists(self.video_file):
                    print("âŒ Animated video not found!")
                    return False
                    
                # Check for voice audio (will be uploaded by n8n)
                audio_files = [f for f in os.listdir(".") if f.endswith(('.mp3', '.wav', '.m4a'))]
                if audio_files:
                    self.audio_file = audio_files[0]
                    print(f"ðŸŽ¤ Found audio: {self.audio_file}")
                else:
                    print("âš ï¸ No audio file found, creating video without voice-over")
                
                print(f"ðŸ“¹ Video: {self.video_file}")
                return True
                
            def get_recipe_text(self):
                """Extract recipe text for overlay"""
                # Get recipe text from GitHub Actions environment
                recipe_from_payload = os.environ.get('RECIPE_TEXT', '')
                if recipe_from_payload:
                    self.recipe_text = recipe_from_payload
                else:
                    self.recipe_text = "Amazing Food Recipe! Follow along for the best results!"
                print(f"ðŸ“ Recipe text: {self.recipe_text[:50]}...")
                
            def create_text_overlay(self):
                """Create stylized text overlay for TikTok"""
                # Split text into multiple lines for better readability
                words = self.recipe_text.split()
                lines = []
                current_line = ""
                
                for word in words:
                    if len(current_line + " " + word) <= 35:  # Optimal line length
                        current_line += " " + word if current_line else word
                    else:
                        lines.append(current_line)
                        current_line = word
                        
                if current_line:
                    lines.append(current_line)
                
                # Limit to 4 lines for mobile viewing
                formatted_text = "\\n".join(lines[:4])
                
                return formatted_text
                
            def create_professional_video(self):
                """Create professional-quality TikTok video with advanced effects"""
                print("ðŸŽ¬ Creating professional TikTok video...")
                
                formatted_text = self.create_text_overlay()
                
                # Advanced FFmpeg command with professional styling
                base_cmd = [
                    'ffmpeg', '-y',
                    '-i', self.video_file
                ]
                
                # Add audio if available
                if self.audio_file:
                    base_cmd.extend(['-i', self.audio_file])
                
                # Create sophisticated filter complex
                filter_parts = []
                
                # Video scaling and effects
                filter_parts.append(
                    "[0:v]scale=1080:1920:force_original_aspect_ratio=decrease,"
                    "pad=1080:1920:(ow-iw)/2:(oh-ih)/2:color=black@1.0,"
                    "eq=brightness=0.05:contrast=1.1[scaled]"
                )
                
                # Advanced text overlay with shadow and styling
                text_filter = (
                    f"[scaled]drawtext="
                    f"text='{formatted_text}':"
                    f"fontfile=/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf:"
                    f"fontsize=36:"
                    f"fontcolor=white:"
                    f"x=(w-text_w)/2:"
                    f"y=h-200:"
                    f"box=1:"
                    f"boxcolor=black@0.8:"
                    f"boxborderw=8:"
                    f"shadowcolor=black@0.7:"
                    f"shadowx=2:"
                    f"shadowy=2[texted]"
                )
                filter_parts.append(text_filter)
                
                # Combine filters
                filter_complex = ";".join(filter_parts)
                
                base_cmd.extend([
                    '-filter_complex', filter_complex,
                    '-map', '[texted]'
                ])
                
                # Audio mapping
                if self.audio_file:
                    base_cmd.extend(['-map', '1:a'])
                    
                # Professional encoding settings
                base_cmd.extend([
                    '-c:v', 'libx264',
                    '-preset', 'medium',
                    '-crf', '23',
                    '-c:a', 'aac',
                    '-b:a', '128k',
                    '-r', '30',
                    '-shortest' if self.audio_file else '-t', '8',
                    self.output_file
                ])
                
                try:
                    print("ðŸš€ Executing advanced video processing...")
                    result = subprocess.run(base_cmd, capture_output=True, text=True, timeout=300)
                    
                    if result.returncode == 0:
                        print("âœ… Professional video created successfully!")
                        self.analyze_output()
                        return True
                    else:
                        print(f"âŒ FFmpeg error: {result.stderr}")
                        return False
                        
                except subprocess.TimeoutExpired:
                    print("âŒ Video processing timed out")
                    return False
                except Exception as e:
                    print(f"âŒ Unexpected error: {e}")
                    return False
                    
            def analyze_output(self):
                """Analyze the created video"""
                if not os.path.exists(self.output_file):
                    return
                    
                # Get video info
                info_cmd = [
                    'ffprobe', '-v', 'quiet', '-print_format', 'json',
                    '-show_format', '-show_streams', self.output_file
                ]
                
                try:
                    result = subprocess.run(info_cmd, capture_output=True, text=True)
                    if result.returncode == 0:
                        info = json.loads(result.stdout)
                        duration = float(info['format']['duration'])
                        size_mb = os.path.getsize(self.output_file) / (1024*1024)
                        
                        print(f"ðŸ“Š Video Analysis:")
                        print(f"   Duration: {duration:.1f} seconds")
                        print(f"   File Size: {size_mb:.1f} MB")
                        print(f"   Format: MP4 (1080x1920)")
                        print(f"   Status: Ready for TikTok/YouTube Shorts! ðŸš€")
                        
                except Exception as e:
                    print(f"âš ï¸ Could not analyze video: {e}")
                    
            def process_video(self):
                """Main processing pipeline"""
                print("ðŸŽ¬ STARTING ADVANCED VIDEO PROCESSING PIPELINE")
                print("=" * 50)
                
                if not self.find_files():
                    return False
                    
                self.get_recipe_text()
                
                success = self.create_professional_video()
                
                if success:
                    print("ðŸŽ‰ TIKTOK MASTERPIECE CREATED!")
                    print(f"ðŸ“± File: {self.output_file}")
                    return True
                else:
                    print("âŒ Video processing failed")
                    return False

        # Execute the video processor
        if __name__ == "__main__":
            processor = TikTokVideoProcessor()
            success = processor.process_video()
            sys.exit(0 if success else 1)
        EOF

    - name: Execute Advanced Video Processing
      env:
        RECIPE_TEXT: ${{ github.event.client_payload.recipe_text }}
      run: |
        echo "ðŸŽ¬ Launching advanced video processing..."
        python3 advanced_video_editor.py

    - name: Upload generated images
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: generated-images
        path: "dalle_generation_*.png"
        retention-days: 30

    - name: Upload animated video
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: animated-video
        path: "final_animation.mp4"
        retention-days: 30

    - name: Upload TikTok Masterpiece
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: tiktok-masterpiece
        path: |
          tiktok_masterpiece.mp4
          final_animation.mp4
          *.mp3
          *.wav
        retention-days: 30

    - name: Create Epic Summary
      if: always()
      run: |
        echo "## ðŸŽ¬ TIKTOK MASTERPIECE GENERATED! ðŸ”¥" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸš€ Your Complete Content Package:" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "tiktok_masterpiece.mp4" ]; then
          VIDEO_SIZE=$(du -h tiktok_masterpiece.mp4 | cut -f1)
          echo "- ðŸŽ¥ **TikTok Ready Video:** tiktok_masterpiece.mp4 ($VIDEO_SIZE)" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“± **Format:** 1080x1920 (Perfect 9:16)" >> $GITHUB_STEP_SUMMARY
          echo "- â±ï¸ **Duration:** ~8 seconds (Optimal for engagement)" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸŽ¤ **Audio:** Professional AI voice-over" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“ **Text:** Recipe overlay with advanced styling" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸŽ¨ **Animation:** Food visuals with perfect effects" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸŽ¯ Ready to Go Viral!" >> $GITHUB_STEP_SUMMARY
        echo "Your professional-grade content is ready for:" >> $GITHUB_STEP_SUMMARY
        echo "- TikTok (optimized for algorithm)" >> $GITHUB_STEP_SUMMARY
        echo "- YouTube Shorts (perfect format)" >> $GITHUB_STEP_SUMMARY
        echo "- Instagram Reels (premium quality)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**ðŸ”¥ AUTOMATION LEVEL: EXPERT ðŸ”¥**" >> $GITHUB_STEP_SUMMARY

    - name: Job completed
      if: always()
      run: echo "âœ… Ultimate Content Creation mission completed"
